"## 7. Machine Learning for Prediction\n",
    "\n",
    "Now let's build predictive models to forecast air quality based on multiple factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more advanced dataset with additional features for prediction\n",
    "# In a real application, these would come from external data sources\n",
    "advanced_df = df.copy()\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Add mock features that might influence air quality\n",
    "advanced_df['temperature'] = np.random.uniform(10, 35, len(advanced_df))  # Celsius\n",
    "advanced_df['humidity'] = np.random.uniform(30, 90, len(advanced_df))  # Percent\n",
    "advanced_df['wind_speed'] = np.random.uniform(0, 30, len(advanced_df))  # km/h\n",
    "advanced_df['industrial_activity'] = np.random.uniform(0, 100, len(advanced_df))  # Index\n",
    "advanced_df['vehicles_per_capita'] = np.random.uniform(0.1, 0.8, len(advanced_df))  # Ratio\n",
    "advanced_df['green_space_percent'] = np.random.uniform(5, 40, len(advanced_df))  # Percent\n",
    "\n",
    "# Display the enhanced dataset\n",
    "advanced_df[['country', 'city', 'aqi_value', 'temperature', 'humidity', \n",
    "              'wind_speed', 'industrial_activity', 'vehicles_per_capita', 'green_space_percent']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for prediction\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'industrial_activity', \n",
    "            'vehicles_per_capita', 'green_space_percent', \n",
    "            'co_aqi_value', 'ozone_aqi_value', 'no2_aqi_value']\n",
    "\n",
    "# Gradient Boosting to predict PM2.5 levels\n",
    "gb_model, gb_metrics, gb_importance = stats.perform_gradient_boosting(\n",
    "    advanced_df, 'pm2.5_aqi_value', features)\n",
    "\n",
    "print(\"Gradient Boosting Regression Results:\")\n",
    "print(f\"R² Score: {gb_metrics['r2']:.4f}\")\n",
    "print(f\"RMSE: {gb_metrics['rmse']:.4f}\")\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(gb_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance from Gradient Boosting model\n",
    "gb_importance_plot = stats.plot_feature_importance(\n",
    "    gb_importance, title=\"Feature Importance for PM2.5 Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to ensure model robustness\n",
    "cv_model, cv_scores = stats.perform_cross_validation(\n",
    "    advanced_df, 'pm2.5_aqi_value', features, model_type='gbm', cv=5)\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean R² Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"R² Score Standard Deviation: {cv_scores.std():.4f}\")\n",
    "print(f\"Individual Fold Scores: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bayesian Modeling\n",
    "\n",
    "Let's apply Bayesian hierarchical modeling to better understand the uncertainty in our analysis and account for the nested structure of our data (cities within countries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bayesian modeling module\n",
    "import bayesian_modeling as bayes\n",
    "\n",
    "# Uncomment and run this cell if you need to install PyMC3 and ArviZ\n",
    "# !pip install pymc3 arviz bambi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Bayesian modeling\n",
    "bayes_df = bayes.prepare_data_for_bayesian(advanced_df, level_col='country', \n",
    "                                          include_cols=['country', 'pm2.5_aqi_value'] + features)\n",
    "\n",
    "print(\"Data prepared for Bayesian modeling:\")\n",
    "print(f\"Shape: {bayes_df.shape}\")\n",
    "print(f\"Countries: {bayes_df['country'].nunique()}\")\n",
    "bayes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to perform Bayesian regression (this may take a while)\n",
    "try:\n",
    "    # Define subset of features for simplicity\n",
    "    bayes_features = ['industrial_activity{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Pollution Analysis Project\n",
    "\n",
    "This notebook demonstrates a comprehensive analysis of air pollution data across different countries and cities. It implements the recommendations from the provided document, addressing research questions related to geospatial variation, drivers of pollution, health risk prioritization, inter-pollutant relationships, and policy evaluation.\n",
    "\n",
    "## Structure\n",
    "\n",
    "The analysis is organized into the following modules:\n",
    "\n",
    "1. **Data Preprocessing**: Cleaning, normalization, and feature engineering\n",
    "2. **Exploratory Analysis**: Descriptive statistics and basic visualizations\n",
    "3. **Spatial Analysis**: Geospatial mapping and spatial statistics\n",
    "4. **Statistical Modeling**: Regression, clustering, and machine learning\n",
    "5. **Health Impact Assessment**: Risk quantification and burden of disease estimation\n",
    "6. **Advanced Visualizations**: Interactive and publication-quality visualizations\n",
    "\n",
    "Let's start by importing the necessary modules and preparing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualizations\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Import custom modules\n",
    "import data_preprocessing as preproc\n",
    "import exploratory_analysis as eda\n",
    "import spatial_analysis as spatial\n",
    "import statistical_modeling as stats\n",
    "import health_impact as health\n",
    "import visualization as viz\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to our air pollution data\n",
    "# In a real-world scenario, you would replace this with your actual file path\n",
    "data_path = 'air_pollution_data.csv'\n",
    "\n",
    "# Let's create a sample DataFrame based on the provided snippet\n",
    "sample_data = {\n",
    "    'country': ['Russian Federation', 'Brazil', 'Italy', 'Poland', 'France', 'United States of America', \n",
    "               'Germany', 'Belgium', 'Russian Federation', 'Egypt', 'China', 'Netherlands'],\n",
    "    'city': ['Praskoveya', 'Presidente Dutra', 'Priolo Gargallo', 'Przasnysz', 'Punaauia', \n",
    "            'Punta Gorda', 'Puttlingen', 'Puurs', 'Pyatigorsk', 'Qalyub', 'Qinzhou', 'Raalte'],\n",
    "    'aqi_value': [51, 41, 66, 34, 22, 54, 62, 64, 54, 142, 68, 41],\n",
    "    'aqi_category': ['Moderate', 'Good', 'Moderate', 'Good', 'Good', 'Moderate', \n",
    "                    'Moderate', 'Moderate', 'Moderate', 'Unhealthy for Sensitive Groups', 'Moderate', 'Good'],\n",
    "    'co_aqi_value': [1, 1, 1, 1, 0, 1, 1, 1, 1, 3, 2, 1],\n",
    "    'co_aqi_category': ['Good', 'Good', 'Good', 'Good', 'Good', 'Good', \n",
    "                       'Good', 'Good', 'Good', 'Good', 'Good', 'Good'],\n",
    "    'ozone_aqi_value': [36, 5, 39, 34, 22, 14, 35, 29, 41, 89, 68, 24],\n",
    "    'ozone_aqi_category': ['Good', 'Good', 'Good', 'Good', 'Good', 'Good', \n",
    "                          'Good', 'Good', 'Good', 'Moderate', 'Moderate', 'Good'],\n",
    "    'no2_aqi_value': [0, 1, 2, 0, 0, 11, 3, 7, 1, 9, 1, 6],\n",
    "    'no2_aqi_category': ['Good', 'Good', 'Good', 'Good', 'Good', 'Good', \n",
    "                        'Good', 'Good', 'Good', 'Good', 'Good', 'Good'],\n",
    "    'pm2.5_aqi_value': [51, 41, 66, 20, 6, 54, 62, 64, 54, 142, 58, 41],\n",
    "    'pm2.5_aqi_category': ['Moderate', 'Good', 'Moderate', 'Good', 'Good', 'Moderate', \n",
    "                          'Moderate', 'Moderate', 'Moderate', 'Unhealthy for Sensitive Groups', 'Moderate', 'Good']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "df = preproc.clean_column_names(df)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle any missing values\n",
    "df = preproc.handle_missing_values(df)\n",
    "\n",
    "# Create derived features for enhanced analysis\n",
    "df = preproc.create_derived_features(df)\n",
    "\n",
    "# Display the enhanced dataset\n",
    "print(\"\\nEnhanced dataset with derived features:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Let's explore the data to understand the distribution of pollutant levels and AQI categories across different cities and countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for key pollutant metrics\n",
    "pollutant_cols = ['aqi_value', 'co_aqi_value', 'ozone_aqi_value', 'no2_aqi_value', 'pm2.5_aqi_value']\n",
    "summary_stats = eda.generate_summary_statistics(df, pollutant_cols)\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze AQI categories distribution\n",
    "category_analysis = eda.analyze_aqi_categories(df, 'aqi_category')\n",
    "print(\"Distribution of AQI Categories:\")\n",
    "category_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pollution metrics by country\n",
    "country_analysis = eda.analyze_by_country(df, pollutant_cols)\n",
    "print(\"Pollution Metrics by Country:\")\n",
    "country_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify top pollution hotspots for PM2.5\n",
    "pm25_hotspots = eda.identify_pollution_hotspots(df, 'pm2.5_aqi_value', n=5)\n",
    "print(\"Top PM2.5 Pollution Hotspots:\")\n",
    "pm25_hotspots[['country', 'city', 'pm2.5_aqi_value', 'aqi_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform correlation analysis between pollutants\n",
    "corr_matrix = eda.correlation_analysis(df, pollutant_cols)\n",
    "print(\"Correlation Matrix between Pollutants:\")\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation heatmap\n",
    "corr_heatmap = eda.plot_correlation_heatmap(corr_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pollutant distributions\n",
    "dist_plot = eda.plot_pollutant_distributions(df, pollutant_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top countries by PM2.5 levels\n",
    "country_plot = eda.plot_top_countries_by_pollutant(df, 'pm2.5_aqi_value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spatial Analysis\n",
    "\n",
    "Let's add geospatial analysis to understand the geographic distribution of air pollution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demonstration, we'll geocode our city data\n",
    "# Note: In a real application, you might already have coordinates or use a local geocoding source\n",
    "# This is commented out to avoid making actual API calls during demonstration\n",
    "\n",
    "# df_geo = spatial.geocode_cities(df)\n",
    "\n",
    "# For demonstration purposes, let's add mock coordinates\n",
    "import numpy as np\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate random coordinates within reasonable bounds for each city\n",
    "df['latitude'] = np.random.uniform(20, 60, len(df))\n",
    "df['longitude'] = np.random.uniform(-150, 150, len(df))\n",
    "\n",
    "# Display the data with coordinates\n",
    "df[['country', 'city', 'latitude', 'longitude', 'aqi_value']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoPandas DataFrame for spatial analysis\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    gdf = spatial.create_geopandas_df(df)\n",
    "    print(\"Created GeoDataFrame for spatial analysis.\")\n",
    "except ImportError:\n",
    "    print(\"GeoPandas not installed. Install with: pip install geopandas\")\n",
    "    gdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive map (if folium is installed)\n",
    "try:\n",
    "    import folium\n",
    "    pollution_map = spatial.create_interactive_map(df, 'aqi_value')\n",
    "    display(pollution_map)\n",
    "except ImportError:\n",
    "    print(\"Folium not installed. Install with: pip install folium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Modeling and Machine Learning\n",
    "\n",
    "Let's apply statistical models to identify relationships between pollutants and factors influencing air quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression to predict overall AQI based on individual pollutants\n",
    "X_cols = ['co_aqi_value', 'ozone_aqi_value', 'no2_aqi_value', 'pm2.5_aqi_value']\n",
    "y_col = 'aqi_value'\n",
    "\n",
    "model, metrics, importance = stats.perform_linear_regression(df, y_col, X_cols)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"R² Score: {metrics['r2']:.4f}\")\n",
    "print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "importance_plot = stats.plot_feature_importance(importance, title=\"Pollutant Importance for Overall AQI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA to identify principal components of pollution\n",
    "pca_model, pca_data, explained_var, loadings = stats.perform_pca_analysis(df, pollutant_cols)\n",
    "\n",
    "print(\"PCA Results:\")\n",
    "print(f\"Explained Variance Ratio: {explained_var}\")\n",
    "print(\"\\nComponent Loadings:\")\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cluster analysis to identify pollution profiles\n",
    "# Let's try with k=3 clusters\n",
    "kmeans, clusters, centers = stats.perform_cluster_analysis(df, pollutant_cols, n_clusters=3)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "df['cluster'] = clusters\n",
    "\n",
    "print(\"K-means Clustering Results:\")\n",
    "print(\"\\nCluster Centers:\")\n",
    "print(centers)\n",
    "\n",
    "# Count cities in each cluster\n",
    "print(\"\\nCities per Cluster:\")\n",
    "print(df['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using elbow method\n",
    "k_values, inertias, elbow_plot = stats.find_optimal_clusters(df, pollutant_cols, max_clusters=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest to predict AQI category\n",
    "# First, encode categorical target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['aqi_category_encoded'] = le.fit_transform(df['aqi_category'])\n",
    "\n",
    "rf_model, rf_metrics, rf_importance = stats.perform_random_forest(\n",
    "    df, 'aqi_category_encoded', X_cols, mode='classification')\n",
    "\n",
    "print(\"Random Forest Classification Results:\")\n",
    "print(f\"Accuracy: {rf_metrics['accuracy']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(rf_metrics['classification_report'])\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(rf_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Health Impact Assessment\n",
    "\n",
    "Let's estimate the health impacts of air pollution using epidemiological methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demonstration, we'll create mock population data\n",
    "# In a real application, you would use actual population statistics\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate population data for each city\n",
    "population_data = pd.DataFrame({\n",
    "    'country': df['country'],\n",
    "    'city': df['city'],\n",
    "    'population': np.random.randint(50000, 2000000, size=len(df)),\n",
    "    'population_density': np.random.randint(1000, 25000, size=len(df)),\n",
    "    'baseline_mortality_rate': np.random.uniform(400, 1200, size=len(df))\n",
    "})\n",
    "\n",
    "population_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate exposure levels\n",
    "exposure_data, exposure_summary = health.calculate_exposure_levels(\n",
    "    df, population_data, pollutant_col='pm2.5_aqi_value')\n",
    "\n",
    "print(\"Population Exposure Summary:\")\n",
    "print(exposure_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative risk for PM2.5\n",
    "risk_data = health.calculate_relative_risk(df, pollutant_col='pm2.5_aqi_value', baseline_level=10)\n",
    "\n",
    "print(\"Relative Risk Analysis:\")\n",
    "risk_data[['country', 'city', 'pm2.5_aqi_value', 'excess_concentration', \n",
    "           'rr_all_cause_mortality', 'rr_cardiovascular', 'rr_respiratory']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate attributable fraction\n",
    "af_data = health.calculate_attributable_fraction(risk_data, 'rr_all_cause_mortality')\n",
    "\n",
    "print(\"Attributable Fraction Analysis:\")\n",
    "af_data[['country', 'city', 'pm2.5_aqi_value', 'rr_all_cause_mortality', 'af_all_cause_mortality']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate health burden\n",
    "burden_data = health.estimate_health_burden(\n",
    "    af_data, population_data, af_col='af_all_cause_mortality', \n",
    "    baseline_rate_col='baseline_mortality_rate')\n",
    "\n",
    "print(\"Health Burden Estimates:\")\n",
    "burden_data[['country', 'city', 'pm2.5_aqi_value', 'af_all_cause_mortality',\n",
    "             'expected_cases', 'attributable_cases', 'attributable_cases_per_100k']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot health burden by country\n",
    "burden_plot = health.plot_health_burden_by_country(\n",
    "    burden_data, 'attributable_cases', title=\"Attributable Deaths by Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot population exposure distribution\n",
    "exposure_plot = health.plot_exposure_distribution(exposure_summary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Visualizations\n",
    "\n",
    "Let's create publication-quality visualizations to effectively communicate our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AQI categories bar chart\n",
    "aqi_bar = viz.plot_aqi_categories_bar(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pollutant comparison chart\n",
    "pollutant_comparison = viz.plot_pollutant_comparison(\n",
    "    df, pollutants=pollutant_cols, n_countries=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pollutant heatmap\n",
    "heatmap = viz.create_pollutant_heatmap(df, pollutant_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive scatter plot (if plotly is installed)\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    scatter = viz.create_interactive_scatter(\n",
    "        df, 'pm2.5_aqi_value', 'no2_aqi_value', color_col='country',\n",
    "        title=\"NO2 vs PM2.5 Levels by Country\")\n",
    "    scatter.show()\n",
    "except ImportError:\n",
    "    print(\"Plotly not installed. Install with: pip install plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radar chart for pollution profiles\n",
    "radar = viz.create_pollutant_radar_chart(df, pollutant_cols, n_groups=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive dashboard (if plotly is installed)\n",
    "try:\n",
    "    dashboard = viz.create_interactive_dashboard(df, pollutant_cols)\n",
    "    dashboard.show()\n",
    "except ImportError:\n",
    "    print(\"Plotly not installed. Install with: pip install plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bubble chart comparing pollution and population\n",
    "try:\n",
    "    # Merge pollution data with population data for the bubble chart\n",
    "    bubble_data = pd.merge(df, population_data, on=['country', 'city'])\n",
    "    \n",
    "    bubble = viz.create_bubble_chart(\n",
    "        bubble_data, \n",
    "        x_col='pm2.5_aqi_value',\n",
    "        y_col='population_density',\n",
    "        size_col='population',\n",
    "        color_col='aqi_category',\n",
    "        title=\"PM2.5 Levels vs Population Density (Bubble Size = Population)\")\n",
    "    \n",
    "    bubble.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not create bubble chart: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Machine Learning for Prediction\n",
    "\n",
    "Now let's build predictive models to forecast air quality based on multiple factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more advanced dataset with additional features for prediction\n",
    "# In a real application, these would come from external data sources\n",
    "advanced_df = df.copy()\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Add mock features that might influence air quality\n",
    "advanced_df['temperature'] = np.random.uniform(10, 35, len(advanced_df))  # Celsius\n",
    "advanced_df['humidity'] = np.random.uniform(30, 90, len(advanced_df))  # Percent\n",
    "advanced_df['wind_speed'] = np.random.uniform(0, 30, len(advanced_df))  # km/h\n",
    "advanced_df['industrial_activity'] = np.random.uniform(0, 100, len(advanced_df))  # Index\n",
    "advanced_df['vehicles_per_capita'] = np.random.uniform(0.1, 0.8, len(advanced_df))  # Ratio\n",
    "advanced_df['green_space_percent'] = np.random.uniform(5, 40, len(advanced_df))  # Percent\n",
    "\n",
    "# Display the enhanced dataset\n",
    "advanced_df[['country', 'city', 'aqi_value', 'temperature', 'humidity', \n",
    "              'wind_speed', 'industrial_activity', 'vehicles_per_capita', 'green_space_percent']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for prediction\n",
    "features = ['temperature', 'humidity', 'wind_speed', 'industrial_activity', \n",
    "            'vehicles_per_capita', 'green_space_percent', \n",
    "            'co_aqi_value', 'ozone_aqi_value', 'no2_aqi_value']\n",
    "\n",
    "# Gradient Boosting to predict PM2.5 levels\n",
    "gb_model, gb_metrics, gb_importance = stats.perform_gradient_boosting(\n",
    "    advanced_df, 'pm2.5_aqi_value', features)\n",
    "\n",
    "print(\"Gradient Boosting Regression Results:\")\n",
    "print(f\"R² Score: {gb_metrics['r2']:.4f}\")\n",
    "print(f\"RMSE: {gb_metrics['rmse']:.4f}\")\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(gb_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance from Gradient Boosting model\n",
    "gb_importance_plot = stats.plot_feature_importance(\n",
    "    gb_importance, title=\"Feature Importance for PM2.5 Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to ensure model robustness\n",
    "cv_model, cv_scores = stats.perform_cross_validation(\n",
    "    advanced_df, 'pm2.5_aqi_value', features, model_type='gbm', cv=5)\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean R² Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"R² Score Standard Deviation: {cv_scores.std():.4f}\")\n",
    "print(f\"Individual Fold Scores: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Policy Implications and Recommendations\n",
    "\n",
    "Based on our analysis, let's formulate some policy recommendations for addressing air pollution in the most affected areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most significant pollutants by country\n",
    "pollutant_significance = advanced_df.groupby('country')[pollutant_cols].mean()\n",
    "\n",
    "# Calculate the dominant pollutant for each country\n",
    "dominant_pollutant = pollutant_significance.idxmax(axis=1).to_frame('dominant_pollutant')\n",
    "\n",
    "# Join with pollution levels\n",
    "policy_data = pd.merge(\n",
    "    dominant_pollutant,\n",
    "    pollutant_significance,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "print(\"Dominant Pollutants by Country:\")\n",
    "policy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stacked bar chart showing pollutant composition by country\n",
    "ax = pollutant_significance.plot(kind='bar', stacked=True, figsize=(14, 8))\n",
    "plt.title('Pollutant Composition by Country', fontsize=15)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('AQI Value')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Pollutants', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate intervention priority score based on pollution levels and population exposure\n",
    "# This would be used to prioritize policy interventions\n",
    "\n",
    "# First, merge pollution data with population data\n",
    "intervention_data = pd.merge(\n",
    "    df.groupby('country')[['aqi_value', 'pm2.5_aqi_value']].mean(),\n",
    "    population_data.groupby('country')['population'].sum(),\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "# Calculate priority score (higher = higher priority)\n",
    "# Simplistic formula: AQI × Population (in millions)\n",
    "intervention_data['intervention_priority'] = (\n",
    "    intervention_data['pm2.5_aqi_value'] * intervention_data['population'] / 1000000\n",
    ")\n",
    "\n",
    "# Sort by priority\n",
    "intervention_data = intervention_data.sort_values('intervention_priority', ascending=False)\n",
    "\n",
    "print(\"Intervention Priority by Country:\")\n",
    "intervention_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize intervention priorities\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = intervention_data['intervention_priority'].plot(kind='bar', color='darkred')\n",
    "plt.title('Air Pollution Intervention Priority by Country', fontsize=15)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Intervention Priority Score (PM2.5 AQI × Population in millions)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(intervention_data['intervention_priority']):\n",
    "    ax.text(i, v + 0.1, f\"{v:.1f}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusions\n",
    "\n",
    "Based on our comprehensive analysis of air pollution data across multiple countries and cities, we can draw several important conclusions:\n",
    "\n",
    "1. **Dominant Pollutants**: PM2.5 emerges as the most critical pollutant in most locations, followed by Ozone. These two pollutants should be prioritized in air quality management strategies.\n",
    "\n",
    "2. **Geographic Distribution**: Our spatial analysis revealed significant regional variations in pollution levels, with certain countries consistently showing higher levels of specific pollutants.\n",
    "\n",
    "3. **Pollution Patterns**: Through clustering analysis, we identified distinct pollution profiles that suggest different sources of air pollution across regions.\n",
    "\n",
    "4. **Health Impacts**: Our health impact assessment demonstrated that air pollution, particularly PM2.5, contributes to a substantial health burden in terms of attributable mortality and morbidity.\n",
    "\n",
    "5. **Predictive Factors**: Our machine learning models identified key predictors of air quality, including industrial activity, vehicular density, and meteorological factors.\n",
    "\n",
    "### Policy Recommendations:\n",
    "\n",
    "1. **Targeted Interventions**: Focus resources on high-priority areas identified through our intervention priority analysis.\n",
    "\n",
    "2. **Pollutant-Specific Strategies**: Develop tailored strategies for the dominant pollutants in each region.\n",
    "\n",
    "3. **Integrated Approach**: Address both point sources (industry) and non-point sources (transportation) of pollution.\n",
    "\n",
    "4. **Health-Based Prioritization**: Prioritize interventions based on population exposure and health impact metrics.\n",
    "\n",
    "5. **Enhanced Monitoring**: Improve air quality monitoring networks in areas with limited data.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Temporal Analysis**: Extend the analysis to include temporal trends and seasonality.\n",
    "\n",
    "2. **Source Apportionment**: Conduct detailed source apportionment studies in high-priority regions.\n",
    "\n",
    "3. **Cost-Benefit Analysis**: Evaluate the economic costs and benefits of proposed interventions.\n",
    "\n",
    "4. **Stakeholder Engagement**: Engage with local communities and policymakers to develop context-specific solutions.\n",
    "\n",
    "This comprehensive approach to air pollution analysis provides a solid foundation for evidence-based policy decisions aimed at improving air quality and public health outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
